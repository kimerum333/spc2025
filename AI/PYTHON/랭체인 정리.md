# 랭체인이란?
- 다양한 llm 을 지원하기 위한 오픈소스 프레임워크
## LLM모델의 종류(메이저)
- openAI 의 챗지피티, 앤트로픽의 클로드, 구글의 제미나이 => 메이저한 3개 LLM 모델
- 커서, 클링, 레오나르도, 감마 등의 유명한 사이트들은 위의 세 LLM모델을 가져다 쓰는 정도의 차이가 있다.
- 커서는 코딩을 잘하는 모델인 엔트로픽 위에서 프롬프트 엔지니어링을 잘 해서 유명세를 얻었다.

## LLM모델의 종류(로컬,라이트)
- 로컬에 두고 쓸 수 있는 경량형 모델들.
- Mistral, LLaMA 등 HuggingFace에 등록된 고성능 오픈소스 모델들도 자주 사용된다.
- 이들은 ollama나 vLLM 등과 함께 사용하면 PC나 서버에 직접 올려서 쓸 수 있다.
- huggingFace => 다양한 로컬 모델들을 다운받아 쓸 수 있는 허브같은 플랫폼

## 프롬프트 템플릿
- 하나의 프롬프트를 만들어놓고 기본 틀에서 ${}만 바꾸는 느낌.
- SQL의 프리페어드 스테이트먼트와 비슷한 문법이더라...
- 너는 ${role} 전문가야. 다음 문장을 분석해줘: "${sentence}"

# 프롬프트 엔지니어링
## 챗지피티에서의 템플릿
### 랭체인 프롬프트 만들 때...(Role 기반)
- system 프롬프트 넣고 => 요즘 모델에서는 이거 필요 없을 수도 있다. (너는 숙련된 프로그래머야.)
- user 메시지를 넣는다.
- assistant 메시지를 넣는다. (과거 히스토리 보존용)

## 프롬프팅에 신경써야 할 파라미터
1. temperature : 소위 말하는 '창의성' 랜덤하게 다른 값으로 튕기는 빈도. 최대값은 0.0부터 1.0 사이의 값을 갖는다.
2. topk / topp : 다음 토큰을 골라내기 위한 샘플링 전략. 
3. topk : 확률이 높은 상위 k개의 후보 중 무작위 선택. 나의 주변 단어 샘플링할 갯수. 50개...(k개의 후보를 모은 뒤 그 안에서 고름)
4. topp : 누적 확률 p가 될때까지 상위 후보를 모은 뒤, 그 안에서 무작위 선택. (topp 가 0.9면 확률 높은 순으로 후보 누적해서 90%될때까지 모은 뒤, 그 안에서 고름)

## 공통 프롬프팅 기법
0. 프롬프팅의 원리 : [트랜스포머는 본인이 학습한 데이터] + [내가 준 이전 문장] 을 바탕으로 다음 문장을 만들어내는 시스템. 즉, [내가 준 이전 문장]을 얼마나 잘 주느냐에 따라 다음 문장이 어떻게 만들어질지가 정해진다.

- 예시 기반 프롬프팅
1. 제로샷 프롬프팅 : 그냥 예시 없이 말 시키고 질문하는 것.
2. 원 샷 프롬프팅 : 응답 예시를 준다.
3. 퓨 샷 프롬프팅 : 예제를 여러개 준다. => 감정 분류 시킬 때, 각 [문장=>감정]별 예시를 하나씩 줘본다.

- 역할 기반 프롬프팅
4. 롤 프롬프팅 : 너는 의사야.

- Chain of Thought(2022~)
5. 추론 과정 설명 : ai가 단계적으로 추론 과정을 보여주도록 유도하는 기법. (다음 문제를 단계별로 풀어보세요. 각 단계마다 무엇을 하는지 설명하면서 진행해주세요:)
6. Self-consistency Prompting (자기 일관성 프롬프팅) : 동일한 문제에 대해 여러 다른 추론 경로를 생성한 후, 가장 일관된 답변을 선택하는 기법
7. ReAct (Reasoning + Acting)
- Chain of Thought에 '행동(Action)'을 결합한 구조
- AI가 추론만 하지 않고, **웹 검색 / 계산기 / 파이썬 실행 등 외부 도구**를 직접 호출함
- LangChain에서는 이를 위해 agent와 tool 시스템을 사용함

- 출력 형식 지정
8. Output Format Specification (출력 형식 지정) : 표 형식, 또는 Json형식 등등의 형식 지정 + 반드시 포함해야 할 정보 지정
9. Constraint Specification (제약 조건 설정) : 200자 이내, 전문용어 사용하지 말고..., 3가지 고려 사항 포함, 감정에 호소하거나 슬픈 표현을 피해라.

10. Multi-Perspective Prompting(다중 관점 프롬프팅) : 관점을 분리해서 병렬 출력
```
재택근무의 효율성에 대해 다음 세 가지 관점에서 분석해주세요:
1. 회사(경영진)의 관점
2. 직원의 관점
3. IT 보안 담당자의 관점
각 관점별로 주요 장점과 단점을 2가지씩 제시해주세요.    
```
11. Instruction Chaining (지시 연쇄) : 다음 단계를 차례대로 수행해주세요:
- 요즘 한국에서 인기 있는 실내 취미 활동 5가지를 나열해주세요.
- 각 취미별로 필요한 초기 비용과 시간 투자를 예상해주세요.
- 그중 직장인이 퇴근 후 시작하기 가장 좋은 취미를 선택하고, 그 이유를 설명해주세요.
- 선택한 취미를 시작하는 초보자를 위한 3단계 입문 가이드를 작성해주세요.
- 이 취미를 1년간 꾸준히 했을 때 얻을 수 있는 긍정적 효과 3가지를 제시해주세요.

12. Structured Tag Prompting
```
훈육 방식에 대한 분석을 다음 태그 구조를 사용해 제공해주세요:

<전통적_방식>
타임아웃, 꾸중 등 전통적 훈육 방식의 특징과 효과
</전통적_방식>

<현대적_방식>
대화 중심, 긍정 강화 등 현대적 훈육 방식의 특징과 효과
</현대적_방식>

<연령별_고려사항>
아이의 나이에 따라 적합한 훈육 방식과 주의점
</연령별_고려사항>

<전문가_조언>
아동 심리학자들이 권장하는 균형 잡힌 접근법
</전문가_조언>

각 섹션을 명확히 구분하여 답변해주세요.
```

13. Feedback Loop Prompting : 초기 응답에 대한 피드백을 통해 개선을 유도
```
제가 작성한 자기소개서 문단을 개선해주세요:
"저는 대학에서 경영학을 전공했고 마케팅에 관심이 많습니다. 학생회 활동도 했고 인턴 경험도 있습니다. 귀사에 입사하면 열심히 일하겠습니다."

먼저 이 자기소개서의 문제점을 지적한 후, 개선된 버전을 작성해주세요. 그리고 어떤 부분이 향상되었는지 설명해주세요.
```

14. Knowledge Boundary Management (지식 한계 관리)
- 기본 개념 : AI는 특정 시점의 데이터까지만 학습되어 있다. 이를 지식 컷오프(지식 단절점)라고 부른다.
- 문제 : 컷오프 이후의 상황을 모르므로 부정확한 정보를 생성할 위험이 있다. 그러나, 모른다고만 하면 도움이 안 된다.
- 지식 한계를 인정하면서도 유용한 답변을 만드는 방법을 제공.
```
2023년까지의 한국 음식 트렌드 정보만을 바탕으로, 2024-2025년에 유행할 가능성이 높은 음식 트렌드를 예측해주세요. 정확한 최신 데이터가 없더라도, 기존 트렌드의 발전 패턴을 기반으로 합리적인 예측을 해주세요. 특히 MZ세대의 소비 경향과 건강 의식주의 추세를 고려해주세요.
```


# 트랜스포머의 구조
## 트랜스포머 이전의 계보도
1. RNN
2. LSTM
3. GRU
- 위의 모델들은 전부 시계열 데이터를 처리하는 전문.
- 자연어를 처리하기 위해, 앞의 문자열을 읽고 뒤의 문자열이 뭐가 나올지 예측해서 대화 능력을 흉내내는 모델.

4. 트랜스포머
- 위의 시계열 데이터 전문 모델들과 달리, 시계열대로 읽는게 아니라 인풋 문자열 전체를 한꺼번에 받아들여서 병렬처리.
- 시계열 데이터의 경우, 포지셔널 인코딩을 붙여서 처리 가능.

## 트랜스포머의 구성요소
- 인코더 : 입력 데이터를 받아서 내부 표현으로 변환 (번역 상황 : 한국어 문자열을 입력=>의미 벡터로 변환)
- 디코더 : 인코더의 출력, 이전까지의 출력을 바탕으로 새로운 출력 생성(의미 벡터=>영어 문장으로 변환)

### 공통 핵심 구성요소
1. 멀티 헤드 어텐션 : 입력의 서로 다른 위치 간 관계를 병렬적으로 학습. 여러 어텐션 헤드로 다양한 의미관계를 동시에 파악.
2. 포지셔널 인코딩 : 순서를 고려하지 않는 트랜스포머에 위치 정보를 추가해주는 벡터값. 보통 사인/코사인으로 계산.
3. 포지션 와이드 피드포워드 네트워크 : 각 토큰 위치마다 독립적으로 적용되는 MLP. 비선형 변환을 담당.
4. 레이어 노멀라이제이션 : 각 층의 출력을 정규화해 학습 안정화 및 성능 향상.
5. 레지듀얼 커넥션 : 입력을 그대로 더해 정보 손실 방지 및 그래디언트 소실 완화.


# 사족들
## 랭체인 문법은 굉장히 빨리 바뀐다.
- LLM.run 으로 돌아가던 적이 있다. 이건 구버전이라 이젠 쓰이지 않는다. 늘 최신 버전으로 업데이트할 수 밖에... => 레퍼런스가 별로 없으니 공식문서를 늘 봐라.
- 요즘은 llm.invoke() / run 은 이제 deprecated
- 과거에는 함수를 통해 메서드 체이닝을 했었다.( chain1 = llm1.chain() ; chain2 = llm2.chain() 이런 식)
- 요즘은 파이프를 써서 체이닝을 한다. ( chain = 전처리 | 모델 | 후처리 | 모델 | 후처리  )

## 랭체인 파이프라인 예시
```python
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda
from langchain_openai import OpenAI

template = PromptTemplate.from_template("너는 숙련된 요리사야. {재료}로 만들 수 있는 요리를 추천해줘.")

llm = OpenAI()
chain = template | llm | RunnableLambda(lambda x: {"추천요리": x.content})
```