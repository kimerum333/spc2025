import os
from dotenv import load_dotenv
from langchain_openai import OpenAI, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda

# ëŸ¬ë„ˆë¸” ëŒë‹¤ ë§ê³ ë„ íŒ¨ìŠ¤ìŠ¤ë£¨ ê°™ì€ ì¢€ ë” ê³ ì°¨ì›ì˜ ì¶”ìƒí™”ëœ íŒŒì´í”„ë¼ì¸ ì‘ì„±ë²•ë“¤ë„ ì¡´ì¬.
from langchain.agents import load_tools, initialize_agent, AgentType

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
print("ğŸ”§ Loading environment variables...")
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
print("ğŸ” API Key ë¡œë“œ ì™„ë£Œ")

# llm = ChatOpenAI(model='gpt-4o',temperature=0.5)
llm_summary = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5)
llm_translate = OpenAI(temperature=0.5)

# agent ì˜ íŠ¹ì§•  : tools. ê° íˆ´ë§ˆë‹¤ í‚¤ê°€ í•„ìš”í•œê²Œ ë³´í†µì´ë‚˜, ëª‡ëª‡ì€ ì˜ˆì™¸. arxiv, ìœ„í‚¤í”¼ë””ì•„
tools = load_tools(["arxiv"])

agent = initialize_agent(
    tools=tools,
    llm=llm_summary,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
)

# ë²ˆì—­ìš© ì²´ì¸ì„ í•˜ë‚˜ ë§Œë“ ë‹¤. by í”„ë¡¬í”„íŠ¸ ì‘ì„±, ì²´ì´ë‹
## í”„ë¡¬í”„íŠ¸ ì‘ì„±
template = """
ë‹¤ìŒ ë¬¸ì¥ì„ í™•ì¸í•˜ê³ , ì˜ì–´ë¡œ ë˜ì–´ìˆë‹¤ë©´ í•œê¸€ë¡œ, í•œê¸€ë¡œ ë˜ì–´ìˆë‹¤ë©´ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜.
ë²ˆì—­í•  ë¬¸ì¥ :
{text_to_translate}
"""
translate_prompt = PromptTemplate.from_template(template)

## ì²´ì´ë‹
translate_chain = (
    translate_prompt
    | llm_translate
    | RunnableLambda(lambda x: {"translated": x.strip()})
)

#ì´ê±´ ì•„ì§ ì œëŒ€ë¡œ ëë‚˜ì§€ ì•Šì€ ì½”ë“œ
full_chain = (
    RunnableLambda(lambda input: {"input": input["query"]})
    | RunnableLambda(agent.invoke)  # ìš”ì•½ ì‹¤í–‰
    | (lambda x: {"text": x["output"]})
    | translate_chain
)

result = agent.invoke(
    {"input": "ìµœê·¼ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì•„ì„œ ìš”ì•½í•´ì¤˜. ì˜ì–´ë¡œ ì‘ë‹µí•´ì¤˜."}
)

translated_result = translate_chain.invoke({"text_to_translate": result["output"]})
print(translated_result)
# print(result['output'])
