import os
from dotenv import load_dotenv
from langchain_openai import OpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
print("ğŸ”§ Loading environment variables...")
load_dotenv()

api_key = os.getenv('OPENAI_API_KEY')
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
print("ğŸ” API Key ë¡œë“œ ì™„ë£Œ")

# LLM êµ¬ì„±
llm = OpenAI(api_key=api_key, temperature=0.5)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
template = """
ë‹¤ìŒ ë‚´ìš©ì„ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì‹œì˜¤:

{input}

ìš”ì•½:
"""
prompt = PromptTemplate.from_template(template)

# ì²´ì¸ êµ¬ì„±: PromptTemplate â†’ LLM â†’ í›„ì²˜ë¦¬(lambdaë¡œ ë”•ì…”ë„ˆë¦¬í™”)
chain = prompt | llm | RunnableLambda(lambda x: {"summary": x.strip()})

# ì…ë ¥ í…ìŠ¤íŠ¸
input_text = """
LangChain is a framework for developing applications powered by language models.
It enables composition of multiple components like prompt templates, models, retrievers, and tools into flexible pipelines.
This helps developers build contextual, responsive, and intelligent LLM-powered applications quickly.
"""

# ì‹¤í–‰
print("ğŸ§  ìš”ì•½ ì‹¤í–‰ ì¤‘...")
result = chain.invoke({"input": input_text})

# ê²°ê³¼ ì¶œë ¥
print("\nâœ… ìš”ì•½ ê²°ê³¼:")
print(result["summary"])
