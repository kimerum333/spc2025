import os
from dotenv import load_dotenv
from langchain_openai import OpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
print("ğŸ”§ Loading environment variables...")
load_dotenv()

api_key = os.getenv('OPENAI_API_KEY')
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤.")
print("ğŸ” API Key ë¡œë“œ ì™„ë£Œ")

# 2. LLM êµ¬ì„±
llm = OpenAI(api_key=api_key, temperature=0.4)

# 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
template = """
ë‹¹ì‹ ì€ íšŒì‚¬ì˜ ìµœê³  ìš´ì˜ ì±…ì„ì(COO)ì…ë‹ˆë‹¤.
ë‹¤ìŒ íŒ€ì—ê²Œ ê³µì‹ì ì¸ íšŒì‚¬ ì´ë©”ì¼ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

íŒ€: {team}
ì´ìŠˆ: {issue}

ì´ë©”ì¼ì€ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:
- ë§íˆ¬ëŠ” ì •ì¤‘í•˜ê³  ë¹„ì¦ˆë‹ˆìŠ¤ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- ë¬¸ì œ ìƒí™©ì„ ì •í™•íˆ ì§šê³ , íŒ€ì— ìš”ì²­í•˜ê±°ë‚˜ ê¶Œì¥í•˜ëŠ” ì¡°ì¹˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì‹­ì‹œì˜¤.
- "ê°ì‚¬í•©ë‹ˆë‹¤."ë¡œ ë§ˆë¬´ë¦¬í•˜ì‹­ì‹œì˜¤.
"""

prompt = PromptTemplate.from_template(template)

# 4. ì²´ì¸ êµ¬ì„±
chain = prompt | llm | RunnableLambda(lambda x: {"email": x.strip()})

# 5. íŒ€ & ì´ìŠˆ ì…ë ¥
teams = [
    "ê°œë°œíŒ€",
    "ë§ˆì¼€íŒ…íŒ€",
    "ì¸ì‚¬íŒ€",
    "ì´ë¬´íŒ€",
    "ì¬ë¬´íŒ€",
]

topics = [
    "ë„ˆí¬ì˜ ë§ì€ ë²„ê·¸ë¡œì¸í•œ ì‚¬ìš©ìë¶ˆë§Œ",
    "ë²„ê·¸ë¡œ ì¤„ì–´ë“œëŠ” ì‚¬ìš©ìë¥¼ ë‹¤ì‹œ ë¶™ì¡ê¸° ìœ„í•œ ì „ëµ",
    "ë²„ê·¸ë¥¼ ë§Œë“œëŠ” ê°œë°œìë¥¼ í•´ê³ í•˜ê¸° ìœ„í•œ ì „ëµ",
    "í•´ê³ ì´í›„, ì§ì›ë“¤ì˜ ë™ê¸°ë¶€ì—¬ë¥¼ ìœ„í•œ ë‹¤ê³¼íŒŒí‹°",
    "ì£¼ì£¼ë“¤ì—ê²Œ ë³´ë‚´ëŠ” ì„œí•œ",
]

# 6. ì‹¤í–‰ ë£¨í”„
print("\nğŸ“§ ì´ë©”ì¼ ìƒì„± ê²°ê³¼:\n")
for team, topic in zip(teams, topics):
    result = chain.invoke({"team": team, "issue": topic})
    print(f"ğŸ“ [{team}]ì—ê²Œ ë³´ë‚´ëŠ” ì´ë©”ì¼:")
    print(result["email"])
    print("\n" + "="*60 + "\n")
