import os
from dotenv import load_dotenv
from flask import Flask, request, jsonify, send_file
from langchain_openai import OpenAI

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
print("ğŸ”§ Loading environment variables...")
load_dotenv()

app = Flask(__name__)

# LLM ì„¤ì •
api_key = os.getenv('OPENAI_API_KEY')
print(f"ğŸ” Loaded API Key: {'âœ…' if api_key else 'âŒ'}")

llm = OpenAI(api_key=api_key, temperature=0.7)

# í…œí”Œë¦¿ í•¨ìˆ˜
def formatPrompt(template, product):
    return template.format(product=product)

# "/" ê²½ë¡œì—ì„œ front.html ë°˜í™˜
@app.route("/")
def index():
    print("ğŸ“„ '/' route accessed - Serving front.html")
    return send_file("front.html")

# ìƒì„± API
@app.route("/generate", methods=["POST"])
def generate():
    print("ğŸ“¥ '/generate' POST request received")
    data = request.get_json()
    print(f"ğŸ§¾ Raw request data: {data}")

    product = data.get("ask", "").strip()
    print(f"ğŸ’¬ Prompt received: {product}")

    if not product:
        return jsonify({"error": "prompt ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

    template = """
    íšŒì‚¬ ì´ë¦„ì„ ì‘ëª…í•˜ê³  ì‹¶ì–´. 
    ë‚˜ì˜ íšŒì‚¬ëŠ” {product} ë§Œë“œëŠ” íšŒì‚¬ì•¼.
    íšŒì‚¬ëª…ì€ í•œì˜ ë³‘ê¸°í•´ì„œ ì•Œë ¤ì£¼ê³  ë¶€ê°€ì ì¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆ.

    ì˜ˆë¥¼ ë“¤ìë©´, ì•„ì¼€ì´ë“œ ê²Œì„ì„ ë§Œë“œëŠ” íšŒì‚¬ëŠ”
    ë§ˆì´ì•„ì¼€ì´ë“œ(MyArcade)

    ê·¸ëŸ¼ ì´ì œ ì‘ëª…í•´ì¤˜:\n
    """

    full_prompt = formatPrompt(template, product)

    try:
        result = llm.generate([full_prompt] * 5)
        outputs = [g[0].text.strip() for g in result.generations]
        print(f"âœ… Generation successful. Outputs: {outputs}")
        return jsonify({"reply": outputs})
    except Exception as e:
        print(f"âŒ Error during generation: {e}")
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    print("ğŸš€ Starting Flask server on port 5000...")
    app.run(port=5000)
